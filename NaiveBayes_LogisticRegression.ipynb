{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"endgame.ipynb","provenance":[],"authorship_tag":"ABX9TyPgo1LFpeC6+HYiOjrnap6j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":286,"metadata":{"id":"qkMV8Cby3uXh","executionInfo":{"status":"ok","timestamp":1643668020217,"user_tz":-120,"elapsed":12729,"user":{"displayName":"George Ko","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05702977528446955241"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=1000,skip_top=50)\n","\n","word_index = tf.keras.datasets.imdb.get_word_index()\n","index2word = dict((i + 3, word) for (word, i) in word_index.items())\n","index2word[0] = '[pad]'\n","index2word[1] = '[bos]'\n","index2word[2] = '[oov]'\n","x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n","x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"]},{"cell_type":"code","source":["vocabulary = list()\n","for text in x_train:\n","  tokens = text.split()\n","  vocabulary.extend(tokens)\n","\n","vocabulary = set(vocabulary)\n","print(len(vocabulary))"],"metadata":{"id":"09YOogh067Fc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","x_train_binary = list()\n","x_test_binary = list()\n","\n","for text in range(500):\n","  tokens = tqdm(x_train[text].split())\n","  binary_vector = list()\n","  for vocab_token in vocabulary:\n","    if vocab_token in tokens:\n","      binary_vector.append(1)\n","    else:\n","      binary_vector.append(0)\n","  x_train_binary.append(binary_vector)\n","\n","x_train_binary = np.array(x_train_binary)\n","\n","for text in range(500):\n","  tokens = tqdm(x_test[text].split())\n","  binary_vector = list()\n","  for vocab_token in vocabulary:\n","    if vocab_token in tokens:\n","      binary_vector.append(1)\n","    else:\n","      binary_vector.append(0)\n","  x_test_binary.append(binary_vector)\n","\n","x_test_binary = np.array(x_test_binary)"],"metadata":{"id":"vAksQ5as7ARM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_x=np.ones(500)\n","for i in range(500):\n","  y_train_x[i]=y_train[i]\n","\n","y_test_x=np.ones(500)\n","for i in range(500):\n","  y_test_x[i]=y_test[i]"],"metadata":{"id":"4wnaSI3cCG9K","executionInfo":{"status":"ok","timestamp":1643668066969,"user_tz":-120,"elapsed":232,"user":{"displayName":"George Ko","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05702977528446955241"}}},"execution_count":289,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test=train_test_split(x_train_binary,y_train_x,test_size=0.20)"],"metadata":{"id":"qrg8CA1yyvtY","executionInfo":{"status":"ok","timestamp":1643668068473,"user_tz":-120,"elapsed":230,"user":{"displayName":"George Ko","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05702977528446955241"}}},"execution_count":290,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","  \n","def accuracy(y_test,predictions):\n","    acc=0\n","    for x in range(y_test.size):\n","      if(y_test[x]==predictions[x]):\n","        acc +=1\n","    acc =acc/len(y_test)\n","    return acc\n","\n","def positive_precision(y_test,predictions):\n","    positive_pres=0\n","    for x in range(y_test.size):\n","      if(y_test[x]==predictions[x] and predictions[x]==1 ):\n","        positive_pres +=1\n","    positive_pres =positive_pres/np.count_nonzero(predictions)\n","    return positive_pres\n","\n","def negative_precision(y_test,predictions):\n","    negative_pres=0\n","    for x in range(y_test.size):\n","      if(y_test[x]==predictions[x] and predictions[x]==0 ):\n","        negative_pres +=1\n","    negative_pres =negative_pres/(len(predictions)-np.count_nonzero(predictions))\n","    return negative_pres\n","\n","def positive_recall(y_test,predictions):\n","    positive_rec=0\n","    for x in range(y_test.size):\n","      if(y_test[x]==predictions[x] and predictions[x]==1 ):\n","        positive_rec +=1\n","    positive_rec =positive_rec/np.count_nonzero(y_test)\n","    return positive_rec\n","\n","def negative_recall(y_test,predictions):\n","    negative_rec=0\n","    for x in range(y_test.size):\n","      if(y_test[x]==predictions[x] and predictions[x]==0 ):\n","        negative_rec +=1\n","    negative_rec =negative_rec/(len(predictions)-np.count_nonzero(y_test))\n","    return negative_rec\n","\n","def macro_recall(recall1,recall2):\n","    return (recall1+recall2)/2\n","def macro_precision(precision1,precision2):\n","    return (precision1+precision2)/2\n","\n","def F1(recall,precision):\n","    return (2*precision*recall)/(precision+recall)\n","\n","\n","def classification_report(y_test,predictions):\n","    print(\"Accuracy is: \",accuracy(y_test,predictions),\" %\")\n","    print(\"Positive precision is: \",positive_precision(y_test,predictions),\" %\")\n","    print(\"Negative precision is: \",negative_precision(y_test,predictions),\" %\")\n","    print(\"Positive recall is: \",positive_recall(y_test,predictions),\" %\")\n","    print(\"Negative recall is: \",negative_recall(y_test,predictions),\" %\")\n","    print(\"F1 is: \",F1(macro_recall(positive_recall(y_test,predictions),negative_recall(y_test,predictions)),macro_precision(positive_precision(y_test,predictions),negative_precision(y_test,predictions))),\" %\")\n","    print(\"\\n\")"],"metadata":{"id":"NAPzJPW-NUYN","executionInfo":{"status":"ok","timestamp":1643663524061,"user_tz":-120,"elapsed":279,"user":{"displayName":"George Ko","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05702977528446955241"}}},"execution_count":258,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","class NaiveBayes():\n","\n","  #Ypologizei thn pithanothta kathe kathgorias, dhladh thn pithanothta na einai kalh kai kakh kritikh/P(C=1),P(C=0)\n","  def class_probability(self,y):\n","    positive = 0\n","    for x in range(y.size):\n","        if(y_train[x] !=0 ):\n","          positive+=1\n","      \n","    positive_prob = (positive+1)/ (y.size+2)#egine laplace\n","    negative_prob = 1-positive_prob\n","    self.class_prob = np.array([positive_prob,negative_prob])\n","\n","  #Ypologizei thn desmevmenh pithanothta kathe idiothtas      \n","  def conditional_probability(self,x,y):\n","        examples= x.shape[0]\n","        feats = x.shape[1]\n","        positives = 0\n","        for i in range(y.size): #ypologizei posa arnytika kai thetika exei to y\n","          if(y[i] !=0 ):\n","            positives+=1\n","\n","        negatives = examples-positives\n","\n","        #arxikopoihsh me assous 2 array poy tha periexoyn tis pithanothtes \n","        self.conditional_prob_0=np.ones(feats)\n","        self.conditional_prob_1=np.ones(feats)\n","\n","        for feat in range(feats): #metraei poses fores mia sugkekrimenh leksh\n","    # einai se thetiko h arnhtiko review. p.x h leksh boring emfanizete 30 fores se thetiko review kai 120 se arnhtiko kai\n","    #meta vriskoume thn pithanothta tous na emfanistoyn \n","\n","          column=[row[feat] for row in x]\n","\n","          count_pos=0 \n","          count_neg=0\n","          for x_i,y_i in zip(column,y_train):\n","            if x_i==1 and y_i!=0:\n","              count_pos=count_pos+1\n","            elif x_i==1 and y_i==0:\n","              count_neg=count_neg+1\n","            self.conditional_prob_0[feat]=count_pos/positives #ypologismos pithanotitas kai eisagogh ston \"thetiko\" array\n","            self.conditional_prob_1[feat]=count_neg/negatives #ypologismos pithanotitas kai eisagogh ston \"arnhtiko\" array\n","\n","          #merge array\n","          self.conditional_prob = np.array([self.conditional_prob_0,self.conditional_prob_1])\n","      \n","        return self.conditional_prob #epistrefei enan array me 2 grammes, h kathe mia exei thn desmevmenh pithanotha kathe idiothtas na einai thetikh \n","                                                                                                            #kai arnhtikh antistoixa gia kathe grammh\n","    \n","  \n","  def predict(self,x):\n","\n","        #.Positive-->Row(0) Negative-->Row(1)\n","        sums=np.ones((2,x.shape[0]))\n","        \n","        for numerator,x_i in enumerate(x):\n","            for numeratorx,feat in enumerate(x_i):\n","                if (feat==1):\n","                    sums[0][numerator]+=np.log(self.conditional_prob[0][numeratorx])\n","                    sums[1][numerator]+=np.log(self.conditional_prob[1][numeratorx])\n","                else:\n","                    sums[0][numerator]+=np.log((1-self.conditional_prob[0][numeratorx]))\n","                    sums[1][numerator]+=np.log((1-self.conditional_prob[1][numeratorx]))\n","        \n","        \n","        sums=np.exp(sums)\n","        sums[0]=sums[0]*self.class_prob[0] #Athroisma P(Xi=xi|C=0)*P(C=0)\n","        sums[1]=sums[1]*self.class_prob[1] #Athroisma P(Xi=xi|C=1)*P(C=1)\n","\n","        #o prediction einai ena aplo array poy periexei mesa 0 h 1 analoga me to an mia idiothta einai se thetiko h arnhtiko review kai epilegete\n","        #kanontas sygkrish  ton grammon toy sums\n","        prediction=np.zeros(x.shape[0])\n","        i=0\n","        for x in range(x.shape[0]):\n","            if(sums[0][x]>sums[1][x]):\n","              prediction[x]=1 \n","            else:\n","              prediction[x]=0\n","        return prediction"],"metadata":{"id":"045apoDc--jw","executionInfo":{"status":"ok","timestamp":1643645696385,"user_tz":-120,"elapsed":311,"user":{"displayName":"George Ko","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05702977528446955241"}}},"execution_count":190,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","class LogisticRegression():\n","\n","  def sigmoid(self,z):\n","        return 1/(1+np.exp(-z))\n","\n","  def __init__ (self,learning_rate, n_iterations):\n","        self.learning_rate=learning_rate\n","        self.n_iterations=n_iterations\n","      \n","  def fit(self,x,y):\n","        examples= x.shape[0]\n","        feats = x.shape[1]\n","        \n","        self.weights=np.zeros(feats)\n","        self.bias=0\n","        \n","        for _ in range(self.n_iterations):\n","            \n","            result=self.sigmoid(np.dot(x,self.weights)+self.bias)\n","\n","            dw = (1/examples)*(np.dot(x.T, (result-y.T).T))\n","            db = (1/examples)*(np.sum(result-y.T))\n","            \n","            self.weights = self.weights - (self.learning_rate * (dw.T))\n","            self.bias = self.bias - (self.learning_rate * db)\n","       \n","    \n","  def predict(self, x):\n","        prediction = np.zeros(x.shape[0])\n","        result=self.sigmoid(np.dot(x,self.weights)+self.bias)\n","        for x in range(result.shape[0]):\n","          if result[x] > 0.5:\n","            prediction[x] = 1\n","        return prediction"],"metadata":{"id":"lxpQKMpiqBvO","executionInfo":{"status":"ok","timestamp":1643645697962,"user_tz":-120,"elapsed":232,"user":{"displayName":"George Ko","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05702977528446955241"}}},"execution_count":191,"outputs":[]},{"cell_type":"code","source":["print(\"Using Naive Bayes Algorithm\")\n","print(\"\\n\")\n","predictionNB=NaiveBayes()\n","predictionNB.class_probability(y_train)\n","predictionNB.conditional_probability(x_train,y_train)\n","predictionNB=predictionNB.predict(x_test)\n","classification_report(y_test,predictionNB)\n","\n","print(\"************************************\")\n","print(\"\\n\")\n","print(\"Now Using Logistic Regression\")\n","print(\"\\n\")\n","predictionLR=LogisticRegression(0.05,1000)\n","predictionLR.fit(x_train,y_train)\n","predictionLR=predictionLR.predict(x_test)\n","predictionLR=np.array(predictionLR)\n","classification_report(y_test,predictionLR)"],"metadata":{"id":"RCAu_Wr7_DMl"},"execution_count":null,"outputs":[]}]}